<div id="ABC">
<div style="padding:5px; border:1px solid #000000; background-color:#C0C0C0; font-size:300%; font-weight:400; color: #000000; width:100%;">
Custom Learning Unit: Cancer Detection Using kNN 
<div style="padding:5px; margin-top:20px; margin-bottom:10px; background-color:#C0C0C0; font-size:30%; font-weight:200; color: #000000; ">
(Thomas Hollis' submission)
</div>
</div>



<div style="padding:5px; border:1px solid #000000; background-color:#f2fafa33; font-size:85%;">
<div style="font-size:118%;">
<b>Abstract:</b><br />
<section begin=abstract />
What is Machine Learning? Why is AI all of a sudden becoming fashionable and widely lauded in newspapers? Can advances in Machine Learning also help advance fields in bioinformatics? The answers to all these questions and more will be provided through a theoretical and practical implementation of the k-Nearest-Neighbours (kNN) algorithm for detecting cancerous cells. 
<section end=abstract />
</div>
<!-- ============================  -->
<hr>
<table>
<tr>
<td style="padding:10px;">
<b>Objectives:</b><br />
* Introduce the concept of Machine Learning
* Give an overview of different algorithms in Machine Learning
* Explain in detail the theory and implementation behind kNN
</td>
<td style="padding:10px;">
<b>Outcomes:</b><br />
* Be able to understand basic concepts in ML
* Gain a good overview of the field
* Be able to implement kNN theoretically from scratch (without packages) and using a standard R package
</td>
</tr>
</table>
<!-- ============================  -->
<hr>
<b>Deliverables:</b><br />
<section begin=deliverables />
<!-- included from "./data/ABC-unit_components.txt", section: "deliverables-time_management" -->
*<b>Time management</b>: Before you begin, estimate how long it will take you to complete this unit. Then, record in your course journal: the number of hours you estimated, the number of hours you worked on the unit, and the amount of time that passed between start and completion of this unit.
<!-- included from "./data/ABC-unit_components.txt", section: "deliverables-journal" -->
*<b>Journal</b>: Document your progress in your [http://steipe.biochemistry.utoronto.ca/abc/students/index.php/Category:BCH441-2018_Journal Course Journal]. Some tasks may ask you to include specific items in your journal. Don't overlook these.
<!-- included from "./data/ABC-unit_components.txt", section: "deliverables-insights" -->
*<b>Insights</b>: If you find something particularly noteworthy about this unit, make a note in your [http://steipe.biochemistry.utoronto.ca/abc/students/index.php/Category:Insights! insights page].
<section end=deliverables />
<!-- ============================  -->
<hr>
<section begin=prerequisites />
<b>Prerequisites:</b><br />
<!-- included from "./data/ABC-unit_components.txt", section: "notes-prerequisites" -->
This unit was designed to have very few prerequisites as it is an introductory unit to Machine Learning applications in bioinformatics. Please do not hesitate to use your search engine of choice for further information if you feel like digging deeper into some of the concepts presented here.
<section end=prerequisites />
<!-- ============================  -->
</div>


__TOC__

= 0. Acknowledgments =

Style inspired from Prof. Steipe's [http://steipe.biochemistry.utoronto.ca/abc/index.php/RPR-Optimization Optimisation (stub)] learning unit.

The kNN cancer dataset was inspired from Bret Lantz's book "Machine Learning with R" <ref>Pakt Publishing. (2013). Machine Learning with R. Retrieved November 13, 2018, from https://www.packtpub.com/big-data-and-business-intelligence/machine-learning-r</ref>.

{{Vspace}}

= 1. Introduction =

Let's start with a quick-fire background Q&A:

* ''What is Machine Learning (ML)?''

Machine Learning is a field of Artificial Intelligence (AI) that leverages statistical computation methods for 'teaching' computers how to extract information from data, without setting explicit programmatic rules. 

Think of this as equivalent to teaching a computer how to walk as follows: first, initially let computer make random trials to learn how to walk ; then punish it more when it reaches small distances and less when in reaches longer distances ; finally computer will eventually learn to walk long distances. Here the explicit programmatic alternative (without using ML) would be to teach the computer how to walk by giving it coordinates of where to place each foot in front of the other.

* ''Why is ML becoming so important in bioinformatics?''

Well there are two types of problems in bioinformatics where ML solutions are preferred to explicit ones. The first type of problem is when we have data where we don't actually know the specific rules for dealing with it (i.e. genetic clustering using k-means). The second type of problem is when the sheer number of rules are so complicated and intertwined that explicitly writing code-based rules would be slower than implementing an ML-based algorithm to approximate solutions (e.g. text mining bioinformatics journals using NLP). 

ML development is much like many fast emerging technological developments. You either get on the train, or you get left behind.

* ''So what are the main fields of applications of ML in bioinformatics?''

The main fields where ML is commonly used in bioinformatics are:

- Disease detection (clustering from image data, disease impact and geo predictions...) 

- Systems biology (genetic algorithms, network modelling...)

- Genomics/Proteomics (clustering, MSA, homology, gene prediction...)

- Text mining (knowledge extraction from bioinformatics papers, annotation databases...)

* ''How does the field of machine learning look like?''

I am a firm believer in starting off an explanation with a high level overview of the field. This helps to understand where we are situated in the current field, what other options there are available and where our algorithm lies amongst its other alternatives. So I built you, dear reader, a nice map (thank Prof. Steipe for his inspiration on this):

[[File:MLmap.png|middle|700px]]

Of course the big disadvantage with these map is that I couldn't include ''all'' the algorithms currently developed in ML. Indeed, I had to pick those that I had come across or the most famous. I also couldn't include lots of interesting material on methods of training (i.e. meta-learning, learning rate, gradient descent optimisation...). If you feel something is missing here, upload an improved version in the [http://steipe.biochemistry.utoronto.ca/abc/students/index.php/File:MLmap.png MLmap wiki page] and include it in your journal!

* ''What is k-Nearest-Neighbours?''

As the MLmap above clearly shows, k-Nearest-Neighbours (kNN) is one of the most basic of many [https://en.wikipedia.org/wiki/Supervised_learning supervised] learning algorithms in the field of ML. More specifically, kNN a type of clustering algorithm used to classify data based on its proximity in data space to other data within the cluster of a particular label.

* ''What is supervised learning?''

Supervised learning is a subset of problems in ML that deal with problems which contain labelled data, as opposed to unsupervised learning which handles problems with unlabelled data. Labelled training data is one which contains both the training features (here: size of cell, shape of cell...) and it's label (here: cancerous or benign...). The label is what we are trying to predict given the input data (features). 

{{Vspace}}

= 2. kNN in Theory =

Let's first look at how kNN works from a theoretical perspective. 

All supervised ML problems have a set of data which contains features (<math>X</math>) and its labels (<math>Y</math>). We always want to attempt to predict the label (<math>Y</math>) using only the features (<math>X</math>). Here, <math>X</math> will be a set of characteristics of the observed cancer cell and <math>Y</math> will be whether it is cancerous or benign.

The kNN algorithm works as follows:
* Train: add all the labelled training data to a <math>d</math>-dimensional 'map' where each point is positioned according to its Euclidean distance from each other in terms of the number (<math>n</math>) of training examples of (<math>X</math>). 
* Predict: predict the class of the new datapoint by simply choosing the most common average class of the k-nearest-neighbours of that point

Euclidean distance is, simply put, a distance metric between two points <math>a</math> and <math>b</math> in <math>d</math>-dimensional space. This is expressed as follows:

<math>||x^{(a)} - x^{(b)}|| = \sqrt{\sum_{j=1}^d (x_j^{(a)} - x_j^{(b)})^2} </math>

If this equation does not make intuitive sense to you, think about the case for two dimensions (Pythagoras) and then picture the case for three (think of the midpoint of a cube). Euclidean distance is simply the shortest straight line distance between two points in [https://en.wikipedia.org/wiki/Euclidean_distance Euclidean space]! 

For simplicity, let us look at the case where we have two dimensions (i.e. two features <math>x_1</math> and <math>x_2</math>) and two classes (i.e. red or black). The best way to visualise how kNN works is by using [https://en.wikipedia.org/wiki/Voronoi_diagram Voronoi Diagrams]:

[[File:Voronoi.png|middle|200px]]

This Voronoi diagram (thanks to Prof. Grosse for these open source Voronoi images) shows all the training data placed on the map ready to accept new datapoints for prediction. Depending on where the datapoint falls in this map it will be predicted as either red or black. Indeed here we are using <math>k = 1</math> as we are only concerned with the single nearest neighbour. Note that in this Voronoi diagram we can clearly see the decision boundaries (in black) which are the collection of points where kNN is equally likely to predict that the datapoint belongs to either class (red or black). Indeed in real life we often have more dimensions (i.e. more axes from 3D onto n-D) and multiple classes (not just binary red/back or true/false).

Now that we understand how kNN initially creates the training map and predicts using training data we must examine how to tune the only hyper-parameter of kNN: <math>k</math>! Let's look at what happens when we vary <math>k</math> from <math>k = 1</math> (LHS) to <math>k = 15</math> (RHS).

[[File:VoronoiK1.png|middle|400px]] [[File:VoronoiK15.png|middle|400px]]

Indeed, we can see that tuning <math>k</math> makes a big difference on the performance. A small <math>k</math> is good for capturing fine grained patterns but can overfit (fail to generalise to future data). On the other hand large <math>k</math> will make stable predictions (will generalise well) but may underfit (fail to capture the complexity of the problem).

In order to tune <math>k</math> we must use different data than what we used to train, otherwise we may fail to generalise. Indeed, you will notice that k = 1 will achieve perfect performance (100%) if we try to predict the same data as the training data. Therefore we must use a fresh, 'unseen' subset of data known as the validation set.

So let's recap what we do

* 1. First, let the ML algorithm (here kNN) learn from some labelled training data (here using the Euclidean Distance metric).
* 2. Second, tune the model's hyper-parameter (here <math>k</math>) on validation data (as a rule of thumb, <math>k < sqrt(n)</math>).
* 3. Thirdly, test our model on test data to evaluate how well it performs. 

The reason why we have these three separate datasets its to avoid 'testing' and 'tuning' using data already known to the algorithm! 

Thus to do this we must split our original dataset into train, validate and test sub-datasets. Usually a good rule of thumb for a reasonable split is 70%, 15%, 15% (although you may want to adjust this depending on how much data is available to you). 

Now that we have our three dataset splits and all the theoretical knowledge we need, let's implement kNN practically to detect cancer!

'''Bonus task: After this section if you really want to test your theoretical and mathematical understanding of kNN, try implementing one from scratch in R. Then compare your implementation to the package approach described in the next section. 
'''
{{Vspace}}

= 3. kNN in Practice =

{{task| 1=
In order to implement your own kNN for cancer detection you either:
* Git clone my [https://github.com/PsiPhiTheta/Bioinformatics-Labs GitHub repo] to your local machine
* Move it into your R working directory
* Load "<code>scripts/ABC-ML-kNN.R</code>" into R like you have done for all your previous learning units
* Load the dataset from the "<code>data</code>" folder as you have done for all your previous learning units
* Go through the code tutorial
Alternatively, if you just want to have a quick overview without executing code yourself (not recommended), you can follow along below.
}}

Okay so let's go through the script from top to bottom in small bite-sized chunks (a bit like an .Rmd file in literate programming). 

<source lang="r">
# Thomas Hollis (BCH441, University of Toronto) -v2.1
#     - Purpose: Implement kNN for cancer detection
#     - Bugs & issues: no bugs, no issues, no warnings
#     - Acknowledgements: thanks to Brett Lantz & Prof. Steipe's learning units which were of great inspiration

# DO NOT SIMPLY "source()" THIS FILE! YOU WILL LOSE (IQ) POINTS FOR DOING SO!

###### 1. Load packages and data ######
if (!require(class, quietly=TRUE)) {
  install.packages("class")
  library(class)
} # used for the kNN function

if (!require(gmodels, quietly=TRUE)) {
  install.packages("gmodels")
  library(gmodels)
} # used for our scoring table

data <- read.csv("wisc_bc_data.csv", stringsAsFactors = FALSE)

data <- data[-1] # Remove the 'id' feature as we won't use it (does not bring us any info)

# Our knn package will need the target feature coded as a factor, so let's do this now
data$diagnosis<- factor(data$diagnosis, levels = c("B", "M"), labels = c("Benign", "Malignant"))
</source>

As usual, importing a few packages, loading the dataset, dropping a feature and reformatting. Nothing special here.

Now let's have a closer look at this dataset

<source lang="r">
###### 2. Exploratory Data Analysis (EDA) ######

summary(data) # Explore the dataset! 31 features describing the cell being observed.
</source>

Here is the output:

[[File:Output1.png|middle|400px]]

If you are wondering what is up with the fancy colours, you really should know about R Studio's dark mode by now...

Now lets move on to preprocessing our dataset!

<source lang="r">
###### 3. Data Preprocessing ######

# We know that kNN is very sensitive to scale so we will have to normalise some data.
# Let's write a simple function for this

normalise <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

dataNorm <- as.data.frame(lapply(data[2:31], normalise)) # Now let's normalise our data, exclude labels

# Time split the data into train, validate and test
dataTrain <- dataNorm[1:398, ] # 70% data for training
dataTrainLab <- data[1:398, 1] # and its labels
dataValidation <- dataNorm[399:484, ] # 15% data for validation
dataValidationLab <- data[399:484, 1] # and its labels
dataTest <- dataNorm[485:569, ] # 15% data for testing
dataTestLab <- data[485:569, 1] # and its labels
</source>

Again nothing too fancy here. Note the splitting of the dataset into train, validate and test.

Onto the kNN implementation... 

<source lang="r">
###### 4. Running kNN ######

# Now that our data is fully ready to feed into our algo, let's feed it in!
# Here we are going to use the class package's "knn()" function
# ?knn for more info

# Let's first compute an upper limit for k (according to our rule of thumb)
(k <- floor(sqrt(nrow(data))))

# Now let's feed the knn package our training data, training labels and test data (without labels!)
dataValidationPred <- knn(train = dataTrain, test = dataValidation, cl = dataTrainLab, k = k)

# Let's have a look at the output
(dataValidationPred) # These should show all the class predictions for the validation set

# Let's see how well our initial model worked on the validation set (leave the test set alone until the end!)
# ?CrossTable for more info
CrossTable(x = dataValidationLab, y = dataValidationPred, prop.chisq=FALSE)

# TASK 1: What information does this table give you?
# TASK 1: How many: true negative? true positive? false positive? false negative?

# ANSWER 1: top left is true negative, bottom right is true positive
# ANSWER 1: bottom left is false negative, top right is false positive

# TASK 2: From this table, what is your classification error rate?

# ANSWER 2: classification error rate is: err = (true negative + true positive)/total
# ANSWER 2: Hence our classification error rate on validation set with k=23 is = 84/86 = 98%!
</source>

Here is the output:

[[File:Output2.png|middle|400px]]

Pretty good performance! But let's try to improve it by tuning <math>k</math>!

<source lang="r">
###### 5. Tuning kNN ######
# Now let's try to find the best possible value of k.
# In normal scenarios the dataset is much bigger so the values of k can be much bigger
# For a large number of different k, we would useually tune k using a grid search
# However, here to keep this exercise interesting the dataset was kept small
# Hence here we have the luxury of being able to try all possible combinations

# TASK 3: tune the kNN! (don't worry about optimising your code, this isn't the goal here)

# ANSWER 3:

# A sensible approach would be to start by creating a function to return the overall performance

performance <- function(label, predictions) {
  acc <- (sum(label == predictions))/(length(label))
  return (acc)
}

# Now we can iterate through all k and get their validation set performance
perf <- 1:floor(sqrt(nrow(data)))

for (i in 1:floor(sqrt(nrow(data)))) {
  k <- i
  dataValidationPred <- knn(train = dataTrain, test = dataValidation, cl = dataTrainLab, k = k)
  perf[i] <- performance(label = dataValidationLab, predictions = dataValidationPred)
  cat("With a k of", k, "we get a performance of:", perf[i], "\n")
} # Best k for me at k=4, k=15, k=16 (I'll pick 16 because of Occam's Razor)

# Bonus marks if you vectorise this code and push it to GitHub!
</source>

Here is the output:

[[File:Output3.png|middle|400px]]

Here we can see that a small k definitely overfits the training data as it gets a worse performance on the validation set. It is so satisfying to see theory so transparently present in implementation.

<source lang="r">
###### 6. Evaluate final model performance ######

# Now we have picked our best k, let's see how well we can classify the test data
k <- 16 # insert your best K here
dataTestPred <- knn(train = dataTrain, test = dataTest, cl = dataTrainLab, k = k) # run on test data
(performance(label = dataValidationLab, predictions = dataValidationPred)) # evaluate (for me ~0.98)

# Write a conclusion in your journal about whether you think a 2% error rate is acceptable
# Take the example of a patient who has tested positive for cancer. Think about Bayes' Rule!

# END
</source>

My own output here was around 98% which is to be expected for this dataset. Note that there are many tricks to push this even further and this is a great starting point for an evaluation unit or for a lengthy journal entry!

{{Vspace}}

= 4. Self-evaluation =

== Question 1 ==

Question: Explain in your own words what ML is, how it works and whether kNN is supervised or unsupervised.

<div class="toccolours mw-collapsible mw-collapsed" style="width:800px">
Answer ...
<div class="mw-collapsible-content">
Machine Learning is a field of Artificial Intelligence (AI) that leverages statistical computation methods for 'teaching' computers how to extract information from data, without setting explicit programmatic rules.

Think of this as equivalent to teaching a computer how to walk as follows: first, initially let computer make random trials to learn how to walk ; then punish it more when it reaches small distances and less when in reaches longer distances ; finally computer will eventually learn to walk long distances. Here the explicit programmatic alternative (without using ML) would be to teach the computer how to walk by giving it coordinates of where to place each foot in front of the other.

kNN is supervised because we provide the "correct" labels in the training data. 
</div>
</div>

== Question 2 ==

Question: What is the metric that kNN uses to assign a data point to a cluster? 

<div class="toccolours mw-collapsible mw-collapsed" style="width:800px">
Answer ...
<div class="mw-collapsible-content">
kNN uses Euclidean distance metric to set its classification as the most common class of its k-nearest-neighbours! 
</div>
</div>

== Question 3 ==

Question: What are hyper-parameters and which is the only hyper-parameter to tune in kNN?

<div class="toccolours mw-collapsible mw-collapsed" style="width:800px">
Answer ...
<div class="mw-collapsible-content">
Hyper-parameters are the inputs of ML algorithms that are not automatically 'learned' on the training data by the algorithm but that must instead be tuned on validation data by the implementor. In kNN, the hyper-parameter is k of course! 
</div>
</div>

== Question 4 ==

Question: What is overfitting and how do you avoid it?

<div class="toccolours mw-collapsible mw-collapsed" style="width:800px">
Answer ...
<div class="mw-collapsible-content">
Overfitting is when your training error rate is very low but this does not generalise to the testing data. Solve this by tuning the hyper-parameter (here k) on the validation data and leave the test data till the end! Fun fact: you can also use [https://en.wikipedia.org/wiki/Regularization_(mathematics) regularisers] to help use Occam's Razor to reduce overfitting.
</div>
</div>

{{Vspace}}

= 5. Notes and references =
<references />

{{Vspace}}

= 6. Further reading, links and resources =

1. Regularisation wiki: https://en.wikipedia.org/wiki/Regularization_(mathematics)

2. ML wiki: https://en.wikipedia.org/wiki/Machine_learning

3. A brilliant course by an ML pioneer (Andrew Ng): https://www.coursera.org/learn/machine-learning

4. kNN wiki: https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm

5. Limitations: kNN is very basic and suffers from the [https://en.wikipedia.org/wiki/Curse_of_dimensionality curse of dimensionality]

{{Vspace}}

----

<b>If in doubt, ask!</b> If anything about this learning unit is not clear to you, do not proceed blindly but ask for clarification. Post your question on the course mailing list: others are likely to have similar problems. Or send an email to your instructor.

----

{{Vspace}}

<div class="about">
<div style="padding:5px; border:1px solid #000000; background-color:#ffffff; width:100%;">
<b>About </b><br />
&nbsp;<br />
<b>Author:</b><br />
:Thomas Hollis <thollis@cs.toronto.edu>
<b>Created:</b><br />
:2018-11-13
<b>Modified:</b><br />
:2018-11-15
<b>Version:</b><br />
:1.2
<b>Version history:</b><br />
*0.1 First stub
*1.1 Theoretical content added
*1.2 Practical content added
</div>
</div>

{{CC-BY}}


<!-- [END] -->
